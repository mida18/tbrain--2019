{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from featexp import get_trend_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv',encoding='big5', low_memory=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 131)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('test.csv',encoding='big5', low_memory=False)\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_train = data.drop('Y1', axis=1)\n",
    "stats = get_trend_stats(data = data_train,target_col='CUS_ID', data_test = data_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from featexp import get_univariate_plots\n",
    "get_univariate_plots(data=data_train, target_col='CUS_ID', data_test=data_test, features_list=['LEVEL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check over NaN & space"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.isnull(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.dropna(how='all').shape #沒有全部皆為NaN值的列"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = data[data.applymap(lambda x: str(x).isspace()) == True].isnull().sum()\n",
    "print(data.shape,\"\\n\",sum(a)) #沒有空格欄位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_data = data.select_dtypes(include='object').columns\n",
    "len(object_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   1)  ordinal feature (replace NaN with 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_features(df):\n",
    "    order_mapping = {'低':1,'中':2,'中高':3,'高':4}\n",
    "    col=['AGE','APC_1ST_AGE','INSD_1ST_AGE','RFM_R','REBUY_TIMES_CNT','LIFE_CNT']\n",
    "    for i in col:\n",
    "        df[i] = df[i].map(order_mapping)\n",
    "        df[i] = df[i].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_object_1 = order_features(data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = order_features(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2-1) nominal feature_Y/N (replace NaN with 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y_N(df):\n",
    "    count = 0\n",
    "    transform = {'Y':1,'N':0}\n",
    "    for i in df.columns:\n",
    "        if re.match(r'IF|FINANCETOOLS|X_|IM_IS|LAST|^[A-Z].*IND$', i):\n",
    "            df[i] = df[i].map(transform)\n",
    "            df[i] = df[i].fillna(2)\n",
    "            count += 1  \n",
    "    print(\"number of Y/N columns ：\", count)         \n",
    "    \n",
    "    try:\n",
    "        df['Y1'] = df['Y1'].map(transform)  # Using 'try' to make sure not to raise error when fitting test data \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Y/N columns ： 79\n"
     ]
    }
   ],
   "source": [
    "data_object_2 = Y_N(data_object_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Y/N columns ： 79\n"
     ]
    }
   ],
   "source": [
    "data_test = Y_N(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2-2) nominal feature_others (make NaN become a kind of category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(df):\n",
    "    col = df.select_dtypes(include='object').columns\n",
    "    col = col.append(pd.Index([\"MARRIAGE_CD\"])) # !!! It's a categorical column in float data type !!! \n",
    "    print('The remaining categorical columns：', len(col), \"\\n\", col)\n",
    "    \n",
    "    c3 = {}\n",
    "    for c in col:\n",
    "        c3[c] = 'ohe_' + c\n",
    "        #df[c] = df[c].fillna(\"NaN\") # to make \"NaN\" also become a kind of category\n",
    "        \n",
    "    df = df.fillna(\"NaN\")  #if use Fill_NA function\n",
    "    df = pd.get_dummies(df, columns=col, drop_first=True, prefix=c3)\n",
    "    \n",
    "    print('Shape：', df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining categorical columns： 5 \n",
      " Index(['GENDER', 'CHARGE_CITY_CD', 'CONTACT_CITY_CD', 'CUST_9_SEGMENTS_CD',\n",
      "       'MARRIAGE_CD'],\n",
      "      dtype='object')\n",
      "Shape： (100000, 153)\n"
     ]
    }
   ],
   "source": [
    "data_object_3 = OHE(data_object_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining categorical columns： 5 \n",
      " Index(['GENDER', 'CHARGE_CITY_CD', 'CONTACT_CITY_CD', 'CUST_9_SEGMENTS_CD',\n",
      "       'MARRIAGE_CD'],\n",
      "      dtype='object')\n",
      "Shape： (150000, 152)\n"
     ]
    }
   ],
   "source": [
    "data_test = OHE(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fill_NaN(df, method):\n",
    "    imr = Imputer(missing_values='NaN', strategy=method, axis=0).fit(df.values)\n",
    "    imputed_data = imr.transform(df.values)\n",
    "    \n",
    "    #turn numpy.ndarray back to dataframe\n",
    "    col={}\n",
    "    for j,c in enumerate(df.columns):\n",
    "        col[c] = imputed_data[:, j]\n",
    "        \n",
    "    df = pd.DataFrame(col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doggy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\doggy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data_object_final = Fill_NaN(data_object_3, 'mean')\n",
    "data_test_final = Fill_NaN(data_test, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_col = []\n",
    "for i in data_object_3.columns:\n",
    "    if len(data_object_3[i].unique()) > 5: #因order_features的unique=5\n",
    "        check_col.append(i)\n",
    "len(check_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_col.remove('CUS_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APC_CNT',\n",
       " 'CUS_ID',\n",
       " 'EDUCATION_CD',\n",
       " 'IM_CNT',\n",
       " 'L1YR_B_ISSUE_CNT',\n",
       " 'MARRIAGE_CD'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.columns) - set(object_data) - set(check_col) #The remaining unchecked columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION_CD\n"
     ]
    }
   ],
   "source": [
    "others = list(set(data.columns) - set(object_data) - set(check_col))\n",
    "others.remove('MARRIAGE_CD')\n",
    "for i in others:\n",
    "    if data_object_3[i].isnull().any() == True:\n",
    "        print(i)\n",
    "        data_object_3[i] = data_object_3[i].fillna(data_object_3[i].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION_CD\n"
     ]
    }
   ],
   "source": [
    "for i in others:\n",
    "    if data_test[i].isnull().any() == True:\n",
    "        print(i)\n",
    "        data_test[i] = data_test[i].fillna(data_test[i].dropna().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_check_IQR(check_col, col_checked, df):\n",
    "    for i in check_col:\n",
    "        col_value = df[i].dropna()\n",
    "        Percentile = np.percentile(col_value.unique(), [0,25,50,75,100])\n",
    "        IQR = Percentile[3] - Percentile[1] #四分位距\n",
    "        UpLimit = Percentile[3] + IQR*1.5 # 約 +2.698 std\n",
    "        DownLimit = Percentile[1] - IQR*1.5\n",
    "\n",
    "        if len(col_value[col_value > UpLimit]) > 0 or len(col_value[col_value < DownLimit]) > 0:\n",
    "            y_1 = sum(df.iloc[col_value[col_value > UpLimit]][\"Y1\"]) + \\\n",
    "                  sum(df.iloc[col_value[col_value < DownLimit]][\"Y1\"])\n",
    "            print('col: %s, Over UpLimit: %d, Under DownLimit: %d, Y=1: %d' % \\\n",
    "                  (i, len(col_value[col_value > UpLimit]),len(col_value[col_value < DownLimit]),y_1))\n",
    "\n",
    "            col_checked.append(i)\n",
    "\n",
    "    print('\\n')\n",
    "    print('col_checked :' , len(col_checked))\n",
    "    print('No outliers: ', set(check_col)-set(col_checked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: INSD_CNT, Over UpLimit: 1, Under DownLimit: 0, Y=1: 0\n",
      "col: ANNUAL_PREMIUM_AMT, Over UpLimit: 2901, Under DownLimit: 0, Y=1: 0\n",
      "col: ANNUAL_INCOME_AMT, Over UpLimit: 3323, Under DownLimit: 0, Y=1: 0\n",
      "col: TOOL_VISIT_1YEAR_CNT, Over UpLimit: 5, Under DownLimit: 0, Y=1: 0\n",
      "col: DIEBENEFIT_AMT, Over UpLimit: 1560, Under DownLimit: 0, Y=1: 0\n",
      "col: DIEACCIDENT_AMT, Over UpLimit: 2732, Under DownLimit: 0, Y=1: 0\n",
      "col: POLICY_VALUE_AMT, Over UpLimit: 865, Under DownLimit: 0, Y=1: 0\n",
      "col: ANNUITY_AMT, Over UpLimit: 97, Under DownLimit: 0, Y=1: 0\n",
      "col: EXPIRATION_AMT, Over UpLimit: 25, Under DownLimit: 0, Y=1: 0\n",
      "col: OUTPATIENT_SURGERY_AMT, Over UpLimit: 39, Under DownLimit: 0, Y=1: 0\n",
      "col: INPATIENT_SURGERY_AMT, Over UpLimit: 11, Under DownLimit: 0, Y=1: 0\n",
      "col: PAY_LIMIT_MED_MISC_AMT, Over UpLimit: 71, Under DownLimit: 0, Y=1: 0\n",
      "col: FIRST_CANCER_AMT, Over UpLimit: 43, Under DownLimit: 0, Y=1: 0\n",
      "col: ILL_ACCELERATION_AMT, Over UpLimit: 252, Under DownLimit: 0, Y=1: 0\n",
      "col: ILL_ADDITIONAL_AMT, Over UpLimit: 1639, Under DownLimit: 0, Y=1: 0\n",
      "col: LONG_TERM_CARE_AMT, Over UpLimit: 47, Under DownLimit: 0, Y=1: 0\n",
      "col: MONTHLY_CARE_AMT, Over UpLimit: 61, Under DownLimit: 0, Y=1: 0\n",
      "col: L1YR_GROSS_PRE_AMT, Over UpLimit: 3651, Under DownLimit: 0, Y=1: 0\n",
      "\n",
      "\n",
      "col_checked : 18\n",
      "No outliers:  {'TERMINATION_RATE', 'LEVEL', 'CHANNEL_B_POL_CNT', 'DISEASES_HOSPITAL_REC_AMT', 'BANK_NUMBER_CNT', 'ACCIDENT_HOSPITAL_REC_AMT', 'BMI', 'CLC_CUR_NUM', 'CHANNEL_A_POL_CNT', 'APC_1ST_YEARDIF', 'OCCUPATION_CLASS_CD', 'AG_NOW_CNT', 'INSD_LAST_YEARDIF_CNT', 'RFM_M_LEVEL', 'L1YR_C_CNT', 'L1YR_A_ISSUE_CNT', 'AG_CNT', 'LIFE_INSD_CNT'}\n"
     ]
    }
   ],
   "source": [
    "col_checked = []\n",
    "outlier_check_IQR(check_col, col_checked, data_object_3)\n",
    "# outlier中沒有y=1者  -->不做特別處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_continuous:21, col_discrete:15, columns need to check:36\n"
     ]
    }
   ],
   "source": [
    "col_continuous, col_discrete = [], []\n",
    "for i in check_col:\n",
    "    #連續型數值(結尾AMT者、BMI、APC_1ST_YEARDIF、TERMINATION_RATE)\n",
    "    if re.match(r'\\w+AMT$|BMI|APC_1ST_YEARDIF|TERMINATION_RATE', i):\n",
    "        col_continuous.append(i)\n",
    "        \n",
    "    #離散型數值\n",
    "    else:\n",
    "        col_discrete.append(i)\n",
    "\n",
    "print('col_continuous:%d, col_discrete:%d, columns need to check:%d' % \\\n",
    "      (len(col_continuous), len(col_discrete), len(col_continuous)+ len(col_discrete)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2-1) col_continuous #21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_check(col, col_nan, df):\n",
    "    for i in col:\n",
    "        if df[i].isnull().any() == True:\n",
    "            col_nan.append(i)\n",
    "            nan_count = len(df[i][df[i].isnull() == True])\n",
    "            y1 = sum(df['Y1'][df[i].isnull() == True])\n",
    "            print('col: %s, NaNs: %d, Y=1: %d, P(NaNs|Y=1): %.4f' % (i, nan_count, y1, y1/2000))\n",
    "\n",
    "    print('\\n')\n",
    "    print('col_nan: ',len(col_nan))\n",
    "    print('No NANs: ', set(col)-set(col_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: APC_1ST_YEARDIF, NaNs: 43282, Y=1: 387, P(NaNs|Y=1): 0.1935\n",
      "col: ANNUAL_PREMIUM_AMT, NaNs: 62445, Y=1: 604, P(NaNs|Y=1): 0.3020\n",
      "col: ANNUAL_INCOME_AMT, NaNs: 39201, Y=1: 407, P(NaNs|Y=1): 0.2035\n",
      "col: BMI, NaNs: 16645, Y=1: 427, P(NaNs|Y=1): 0.2135\n",
      "col: TERMINATION_RATE, NaNs: 43282, Y=1: 387, P(NaNs|Y=1): 0.1935\n",
      "col: DIEBENEFIT_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: DIEACCIDENT_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: POLICY_VALUE_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: ANNUITY_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: EXPIRATION_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: ACCIDENT_HOSPITAL_REC_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: DISEASES_HOSPITAL_REC_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: OUTPATIENT_SURGERY_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: INPATIENT_SURGERY_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: PAY_LIMIT_MED_MISC_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: FIRST_CANCER_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: ILL_ACCELERATION_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: ILL_ADDITIONAL_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: LONG_TERM_CARE_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "col: MONTHLY_CARE_AMT, NaNs: 27540, Y=1: 333, P(NaNs|Y=1): 0.1665\n",
      "\n",
      "\n",
      "col_nan:  20\n",
      "No NANs:  {'L1YR_GROSS_PRE_AMT'}\n"
     ]
    }
   ],
   "source": [
    "col_continuous_nan = []\n",
    "NaN_check(col_continuous, col_continuous_nan, data_object_3)\n",
    "# APC_1ST_YEARDIF、ANNUAL_PREMIUM_AMT、ANNUAL_INCOME_AMT、 BMI、TERMINATION_RATE --> 用 KNN Regression 填補\n",
    "# 其他 --> 用 mean 填補"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN填補：https://mp.weixin.qq.com/s?__biz=MzIzNDk0ODIxNg==&mid=2247483697&idx=1&sn=769babea47a36fcd2eb27e9b5586b227&chksm=e8efd226df985b3049d98471c463705161e8c2412e28e5f5d09dc6e68c675875799bc56d9621&mpshare=1&scene=1&srcid=1019sGnZIzqL4buSlqvXwydT#rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "def find_no_nan_columns(df):\n",
    "    remain_nan_cols = df.isnull().any() [df.isnull().any()== True].index.tolist()\n",
    "    all_cols =  df.columns.tolist()\n",
    "    all_cols.remove('CUS_ID')\n",
    "    try:\n",
    "        all_cols.remove('Y1')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    no_nan_cols = list(set(all_cols) - set(remain_nan_cols))\n",
    "    return no_nan_cols\n",
    "\n",
    "def knn_train_test(target_col, df, no_nan_cols):\n",
    "    train_y = df[target_col][df[target_col].isnull() == False] #目標欄位下的非NAN值\n",
    "    train_x = df[df[target_col].isnull() == False].loc[:,no_nan_cols] #行列都沒有NAN值者\n",
    "    test_x = df[df[target_col].isnull() == True].loc[:,no_nan_cols] #目標欄位下含NAN值者的其餘非NAN列值\n",
    "    return train_y, train_x, test_x\n",
    "\n",
    "def knn_missing_filled(train_x, train_y, test_x, k = 3, dispersed = True):\n",
    "    if dispersed:\n",
    "        clf = KNeighborsClassifier(n_neighbors = k, weights = \"distance\")\n",
    "    else:\n",
    "        clf = KNeighborsRegressor(n_neighbors = k, weights = \"distance\")\n",
    "    \n",
    "    clf.fit(train_x, train_y)\n",
    "    return test_x.index, clf.predict(test_x)\n",
    "\n",
    "def filled_pred_to_data(target_columns, df , n=3, data_type=True):\n",
    "    for i in target_columns:\n",
    "        no_nan_cols = find_no_nan_columns(df)\n",
    "        train_y, train_x, test_x =  knn_train_test(i, df, no_nan_cols)\n",
    "        index, pred = knn_missing_filled( train_x, train_y, test_x, k = n, dispersed = data_type)\n",
    "        df.loc[index, i] = pred\n",
    "        print(i,\" complete\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['APC_1ST_YEARDIF','ANNUAL_PREMIUM_AMT','ANNUAL_INCOME_AMT','BMI','TERMINATION_RATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APC_1ST_YEARDIF  complete\n",
      "ANNUAL_PREMIUM_AMT  complete\n",
      "ANNUAL_INCOME_AMT  complete\n",
      "BMI  complete\n",
      "TERMINATION_RATE  complete\n"
     ]
    }
   ],
   "source": [
    "data_train_knn = filled_pred_to_data(target_cols, data_object_3, n=5, data_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APC_1ST_YEARDIF  complete\n",
      "ANNUAL_PREMIUM_AMT  complete\n",
      "ANNUAL_INCOME_AMT  complete\n",
      "BMI  complete\n",
      "TERMINATION_RATE  complete\n"
     ]
    }
   ],
   "source": [
    "data_test_knn = filled_pred_to_data(target_cols, data_test, n=5, data_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = [x for x in col_continuous_nan if x not in target_cols]\n",
    "for i in others:\n",
    "        data_train_knn[i] = data_train_knn[i].fillna(data_train_knn[i].dropna().mean())\n",
    "        data_test_knn[i] = data_test_knn[i].fillna(data_test_knn[i].dropna().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2-2) col_discrete #15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Outlier_check_plot\n",
    "for i in col_discrete:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('train')\n",
    "    sns.boxplot(y=i, data=data_train_knn.dropna())\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('test')\n",
    "    sns.boxplot(y=i, data=data_test_knn.dropna())\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: OCCUPATION_CLASS_CD, NaNs: 3960, Y=1: 286, P(NaNs|Y=1): 0.1430\n",
      "col: LEVEL, NaNs: 43305, Y=1: 390, P(NaNs|Y=1): 0.1950\n",
      "col: RFM_M_LEVEL, NaNs: 43282, Y=1: 387, P(NaNs|Y=1): 0.1935\n",
      "col: L1YR_C_CNT, NaNs: 87936, Y=1: 1436, P(NaNs|Y=1): 0.7180\n",
      "col: INSD_LAST_YEARDIF_CNT, NaNs: 171, Y=1: 64, P(NaNs|Y=1): 0.0320\n",
      "\n",
      "\n",
      "col_nan:  5\n",
      "No NANs:  {'CHANNEL_B_POL_CNT', 'BANK_NUMBER_CNT', 'INSD_CNT', 'CLC_CUR_NUM', 'CHANNEL_A_POL_CNT', 'AG_NOW_CNT', 'TOOL_VISIT_1YEAR_CNT', 'L1YR_A_ISSUE_CNT', 'AG_CNT', 'LIFE_INSD_CNT'}\n"
     ]
    }
   ],
   "source": [
    "col_discrete_nan = []\n",
    "NaN_check(col_discrete, col_discrete_nan, data_object_3)\n",
    "# Notice：L1YR_C_CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y1=1:  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 29.0]\n",
      "Y1=0:  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 21.0, 22.0, 23.0, 24.0, 25.0, 27.0, 29.0, 30.0, 31.0, 35.0, 37.0, 41.0]\n",
      "test:  [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 29.0, 47.0]\n"
     ]
    }
   ],
   "source": [
    "# check 'L1YR_C_CNT' -not nan values\n",
    "a = data_train_knn['L1YR_C_CNT'][data_train_knn['L1YR_C_CNT'].isnull() == False]\n",
    "print('Y1=1: ', sorted(a[data_train_knn[\"Y1\"]==1].unique()))\n",
    "print('Y1=0: ', sorted(a[data_train_knn[\"Y1\"]==0].unique()))\n",
    "print('test: ', sorted(data_test_knn['L1YR_C_CNT'][data_test_knn['L1YR_C_CNT'].isnull() == False].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doggy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\doggy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# check 'L1YR_C_CNT' -create new column(L1YR_C_CNT <= 15 = 1 else = 0)\n",
    "new_col = 'L1YR_C_CNT_over15'\n",
    "old_col = 'L1YR_C_CNT'\n",
    "data_train_knn[new_col] = 0\n",
    "index = data_train_knn[old_col][data_train_knn[old_col] <= 15].index.tolist()\n",
    "data_train_knn[new_col][index] = 1\n",
    "\n",
    "data_test_knn[new_col]=0\n",
    "index = data_test_knn[old_col][data_test_knn[old_col] <= 15].index.tolist()\n",
    "data_test_knn[new_col][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_corr: 0.0091 | new_corr: 0.0708\n"
     ]
    }
   ],
   "source": [
    "print('origin_corr: %.4f | new_corr: %.4f' % \\\n",
    "      (data_train_knn['L1YR_C_CNT'].corr(data_train_knn['Y1']),\\data_train_knn['L1YR_C_CNT_over15'].corr(data_train_knn['Y1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['L1YR_C_CNT', 'LEVEL', 'RFM_M_LEVEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1YR_C_CNT  complete\n",
      "LEVEL  complete\n",
      "RFM_M_LEVEL  complete\n"
     ]
    }
   ],
   "source": [
    "data_train_knn = filled_pred_to_data(target_cols, data_train_knn, n=5, data_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1YR_C_CNT  complete\n",
      "LEVEL  complete\n",
      "RFM_M_LEVEL  complete\n"
     ]
    }
   ],
   "source": [
    "data_test_knn = filled_pred_to_data(target_cols, data_test_knn, n=5, data_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = [x for x in col_discrete_nan if x not in target_cols]\n",
    "for i in others:\n",
    "        data_train_knn[i] = data_train_knn[i].fillna(data_train_knn[i].dropna().mean())\n",
    "        data_test_knn[i] = data_test_knn[i].fillna(data_test_knn[i].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train shape:  (100000, 154) / Final test shape:  (150000, 153)\n"
     ]
    }
   ],
   "source": [
    "print('Final train shape: ',data_train_knn.shape, '/','Final test shape: ',data_test_knn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_knn.to_csv('train_reprocess_knn_v2.csv',index=False,encoding='big5')\n",
    "data_test_knn.to_csv('test_reprocess_knn_v2.csv',index=False,encoding='big5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_reprocess_knn_v2.csv',encoding='big5', low_memory=False)\n",
    "test = pd.read_csv('test_reprocess_knn_v2.csv',encoding='big5', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94207"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train['CUS_ID']).difference(test['CUS_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_compare_and_drop(df, target_cols, new_col, drop_col):\n",
    "    #刪除相關係數小於新增欄位者\n",
    "    print(new_col, df[new_col].corr(df['Y1']))\n",
    "    for i in target_cols:\n",
    "        print(i, df[i].corr(df['Y1']))\n",
    "        if abs(df[i].corr(df['Y1'])) < abs(df[new_col].corr(df['Y1'])):\n",
    "            drop_col.append(i)\n",
    "    return drop_col\n",
    "\n",
    "def relation_print(x1_col, x2_col):\n",
    "    print(x1_col +'： %.5f' % train[x1_col].corr(train['Y1']),'\\n',\n",
    "          x2_col +'： %.5f' % train[x2_col].corr(train['Y1']))\n",
    "    \n",
    "def plot_count(x, data):\n",
    "    sns.countplot(x= x, data=data)\n",
    "    plt.title(\"cor: %.4f\" % train[x].corr(train['Y1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train： (100000, 154), test： (150000, 153)\n"
     ]
    }
   ],
   "source": [
    "print(\"train： %s, test： %s\" % (train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISSUE_IND_SUM 0.11223029052368377\n",
      "IF_ISSUE_A_IND 0.008663317877697632\n",
      "IF_ISSUE_B_IND 0.020617739022457327\n",
      "IF_ISSUE_C_IND 0.027731887229823667\n",
      "IF_ISSUE_D_IND 0.04078368311190528\n",
      "IF_ISSUE_E_IND 0.0023859095550657346\n",
      "IF_ISSUE_F_IND 0.01065180753647559\n",
      "IF_ISSUE_G_IND 0.03342295287227516\n",
      "IF_ISSUE_H_IND 0.005114230284501293\n",
      "IF_ISSUE_I_IND 0.103050244565999\n",
      "IF_ISSUE_J_IND 0.07464773664538958\n",
      "IF_ISSUE_K_IND 0.004107279945545776\n",
      "IF_ISSUE_L_IND 0.01991533943111337\n",
      "IF_ISSUE_M_IND -4.108476040975764e-18\n",
      "IF_ISSUE_N_IND 0.041581561746040406\n",
      "IF_ISSUE_O_IND -0.0015310220811699633\n",
      "IF_ISSUE_P_IND 0.05069155057720931\n",
      "IF_ISSUE_Q_IND 0.09783821318614783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IF_ISSUE_A_IND',\n",
       " 'IF_ISSUE_B_IND',\n",
       " 'IF_ISSUE_C_IND',\n",
       " 'IF_ISSUE_D_IND',\n",
       " 'IF_ISSUE_E_IND',\n",
       " 'IF_ISSUE_F_IND',\n",
       " 'IF_ISSUE_G_IND',\n",
       " 'IF_ISSUE_H_IND',\n",
       " 'IF_ISSUE_I_IND',\n",
       " 'IF_ISSUE_J_IND',\n",
       " 'IF_ISSUE_K_IND',\n",
       " 'IF_ISSUE_L_IND',\n",
       " 'IF_ISSUE_M_IND',\n",
       " 'IF_ISSUE_N_IND',\n",
       " 'IF_ISSUE_O_IND',\n",
       " 'IF_ISSUE_P_IND',\n",
       " 'IF_ISSUE_Q_IND']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 目前\"壽險保單\"持有有效主約件數\n",
    "col_ind = [i for i in train.columns if re.match(r'IF_ISSUE_._IND', i)]\n",
    "train['ISSUE_IND_SUM'] = train[col_ind].sum(axis=1)\n",
    "test['ISSUE_IND_SUM'] = test[col_ind].sum(axis=1)\n",
    "\n",
    "drop_col = []\n",
    "corr_compare_and_drop(train, col_ind, 'ISSUE_IND_SUM', drop_col)\n",
    "\n",
    "train = train.drop(drop_col, axis=1)\n",
    "test = test.drop(drop_col, axis=1)\n",
    "print(\"train： %s, test： %s\" % (train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISSUE_ADD_SUM 0.0884988904409944\n",
      "IF_ADD_F_IND 0.0401263641862706\n",
      "IF_ADD_L_IND 0.0940249989927532\n",
      "IF_ADD_Q_IND 0.09406823613616394\n",
      "IF_ADD_G_IND 0.004714228362330166\n",
      "IF_ADD_R_IND 0.06660611264631974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IF_ADD_F_IND', 'IF_ADD_G_IND', 'IF_ADD_R_IND']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 目前\"壽險保單\"持有有效附約件數\n",
    "col_ind = [i for i in train.columns if re.match(r'IF_ADD_._IND', i)]\n",
    "train['ISSUE_ADD_SUM'] = train[col_ind].sum(axis=1)\n",
    "test['ISSUE_ADD_SUM'] = test[col_ind].sum(axis=1)\n",
    "\n",
    "drop_col = []\n",
    "corr_compare_and_drop(train, col_ind, 'ISSUE_ADD_SUM', drop_col)\n",
    "\n",
    "train = train.drop(drop_col, axis=1)\n",
    "test = test.drop(drop_col, axis=1)\n",
    "print(\"train： %s, test： %s\" % (train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNUAL_INCOME_minus_PREMIUM:  0.027471924531535803\n",
      "ANNUAL_INCOME_AMT： 0.00894 \n",
      " ANNUAL_PREMIUM_AMT： 0.00335\n"
     ]
    }
   ],
   "source": [
    "# 3. 年收入 > 年繳化保費 ? \n",
    "a = train['ANNUAL_INCOME_AMT'].rank() - train['ANNUAL_PREMIUM_AMT'].rank()\n",
    "train['ANNUAL_INCOME_minus_PREMIUM'] = a.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "b = test['ANNUAL_INCOME_AMT'].rank() - test['ANNUAL_PREMIUM_AMT'].rank()\n",
    "test['ANNUAL_INCOME_minus_PREMIUM'] = b.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print('ANNUAL_INCOME_minus_PREMIUM: ',train['ANNUAL_INCOME_minus_PREMIUM'].corr(train['Y1']))\n",
    "relation_print('ANNUAL_INCOME_AMT','ANNUAL_PREMIUM_AMT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train： (100000, 135), test： (150000, 134)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(['ANNUAL_INCOME_AMT','ANNUAL_PREMIUM_AMT'], axis=1)\n",
    "test = test.drop(['ANNUAL_INCOME_AMT','ANNUAL_PREMIUM_AMT'], axis=1)\n",
    "print(\"train： %s, test： %s\" % (train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM_IS_SUM_IND 0.07178148299138282\n",
      "IM_IS_A_IND 0.012886988755502378\n",
      "IM_IS_B_IND 0.05929916132453058\n",
      "IM_IS_C_IND 0.040783574215572806\n",
      "IM_IS_D_IND 0.04803408184577384\n",
      "train： (100000, 158), test： (150000, 157)\n"
     ]
    }
   ],
   "source": [
    "# 4. 是否持有特定商品(A-D)\n",
    "col_ind = [i for i in train.columns if re.match(r'IM_IS_._IND', i)]\n",
    "train['IM_IS_SUM_IND'] = train[col_ind].sum(axis=1)\n",
    "test['IM_IS_SUM_IND'] = test[col_ind].sum(axis=1)\n",
    "\n",
    "drop_col = []\n",
    "corr_compare_and_drop(train, col_ind, 'IM_IS_SUM_IND', drop_col)\n",
    "\n",
    "train = train.drop(drop_col, axis=1)\n",
    "test = test.drop(drop_col, axis=1)\n",
    "print(\"train： %s, test： %s\" % (train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_reprocess_knn_v2_newcolumns.csv',index=False,encoding='big5')\n",
    "test.to_csv('test_reprocess_knn_v2_newcolumns.csv',index=False,encoding='big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
